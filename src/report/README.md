# æŠ¥å‘Šæ¨¡å—

## åŠŸèƒ½æ¦‚è¿°

è´Ÿè´£æµ‹è¯•ç»“æœçš„æ™ºèƒ½åˆ†æã€æŠ¥å‘Šç”Ÿæˆå’Œä¼˜åŒ–å»ºè®®ï¼Œæä¾›åŸºäºAIçš„æ·±åº¦åˆ†æå’Œæ™ºèƒ½ä¼˜åŒ–æ–¹æ¡ˆã€‚

## æ¨¡å—ç»„æˆ

### 1. ç»“æœåˆ†æå™¨ (analyzer.py)
- æµ‹è¯•ç»“æœæ·±åº¦åˆ†æ
- æ€§èƒ½è¶‹åŠ¿åˆ†æ
- å…³è”æ€§åˆ†æ
- æ ¹å› åˆ†æ

### 2. æŠ¥å‘Šç”Ÿæˆå™¨ (generator.py)
- å¤šæ ¼å¼æŠ¥å‘Šç”Ÿæˆ
- æ™ºèƒ½æŠ¥å‘Šæ¨¡æ¿
 å¯è§†åŒ–å›¾è¡¨ç”Ÿæˆ
- è‡ªåŠ¨æŠ¥å‘Šåˆ†å‘

### 3. ä¼˜åŒ–å»ºè®®å™¨ (optimizer.py)
- æ€§èƒ½ä¼˜åŒ–å»ºè®®
- æç¤ºè¯æ”¹è¿›æ–¹æ¡ˆ
- èµ„æºé…ç½®ä¼˜åŒ–
- æœ€ä½³å®è·µæ¨è

## åŠŸèƒ½ç‰¹æ€§

- ğŸ§  AIæ™ºèƒ½åˆ†æ
- ğŸ“Š å¤šç»´åº¦æ•°æ®æŒ–æ˜
- ğŸ“„ ä¸“ä¸šæŠ¥å‘Šç”Ÿæˆ
- ğŸ’¡ ä¼˜åŒ–å»ºè®®æ¨è
- ğŸ“ˆ è¶‹åŠ¿é¢„æµ‹åˆ†æ
- ğŸ¯ ç²¾å‡†é—®é¢˜å®šä½

## ä½¿ç”¨ç¤ºä¾‹

```python
# ç»“æœåˆ†æ
from src.report import ResultAnalyzer

analyzer = ResultAnalyzer()

# åŸºç¡€åˆ†æ
basic_analysis = analyzer.analyze_basic_metrics(test_results)
print(f"å¹³å‡æ‰§è¡Œæ—¶é—´: {basic_analysis.avg_execution_time}")

# è¶‹åŠ¿åˆ†æ
trend_analysis = analyzer.analyze_trends(historical_data)
print(f"æ€§èƒ½è¶‹åŠ¿: {trend_analysis.performance_trend}")

# å…³è”æ€§åˆ†æ
correlation = analyzer.analyze_correlations(test_results)
print(f"å½±å“æœ€å¤§çš„å› ç´ : {correlation.top_factors}")

# æŠ¥å‘Šç”Ÿæˆ
from src.report import ReportGenerator

generator = ReportGenerator()

# ç”ŸæˆHTMLæŠ¥å‘Š
html_report = generator.generate_html_report(
    analysis_results=basic_analysis,
    template="modern",
    output_file="report.html"
)

# ç”ŸæˆPDFæŠ¥å‘Š
pdf_report = generator.generate_pdf_report(
    analysis_results=basic_analysis,
    output_file="report.pdf",
    include_charts=True
)

# ä¼˜åŒ–å»ºè®®
from src.report import OptimizationAdvisor

advisor = OptimizationAdvisor()
recommendations = advisor.get_recommendations(test_results, analysis_data)

for rec in recommendations:
    print(f"å»ºè®®: {rec.description}")
    print(f"é¢„æœŸæå‡: {rec.expected_improvement}")
    print(f"å®æ–½éš¾åº¦: {rec.difficulty}")
```

## åˆ†æç»´åº¦

### 1. æ€§èƒ½åˆ†æ
```python
@dataclass
class PerformanceAnalysis:
    execution_time_metrics: Dict[str, float]  # å¹³å‡å€¼ã€P95ã€P99ç­‰
    throughput_metrics: Dict[str, float]        # ååé‡æŒ‡æ ‡
    resource_utilization: Dict[str, float]      # èµ„æºä½¿ç”¨ç‡
    scalability_metrics: Dict[str, float]      # å¯æ‰©å±•æ€§æŒ‡æ ‡
    efficiency_score: float                      # æ•ˆç‡è¯„åˆ† (0-100)
```

### 2. è´¨é‡åˆ†æ
```python
@dataclass
class QualityAnalysis:
    success_rate: float                         # æˆåŠŸç‡
    error_distribution: Dict[str, int]           # é”™è¯¯åˆ†å¸ƒ
    reliability_score: float                     # å¯é æ€§è¯„åˆ†
    consistency_metrics: Dict[str, float]       # ä¸€è‡´æ€§æŒ‡æ ‡
    stability_trend: str                        # ç¨³å®šæ€§è¶‹åŠ¿
```

### 3. æˆæœ¬åˆ†æ
```python
@dataclass
class CostAnalysis:
    token_consumption: Dict[str, float]         # Tokenæ¶ˆè€—ç»Ÿè®¡
    cost_breakdown: Dict[str, float]            # æˆæœ¬åˆ†è§£
    cost_efficiency: float                       # æˆæœ¬æ•ˆç‡
    optimization_potential: float               # ä¼˜åŒ–æ½œåŠ›
    roi_estimation: float                       # æŠ•èµ„å›æŠ¥ç‡ä¼°ç®—
```

## æŠ¥å‘Šæ¨¡æ¿

### 1. æ‰§è¡Œæ‘˜è¦æŠ¥å‘Š
```markdown
# æµ‹è¯•æ‰§è¡Œæ‘˜è¦

## æ ¸å¿ƒæŒ‡æ ‡
- **æ€»ä½“è¯„åˆ†**: 85/100
- **æˆåŠŸç‡**: 95.2%
- **å¹³å‡æ‰§è¡Œæ—¶é—´**: 2.3s
- **æˆæœ¬æ•ˆç‡**: ä¼˜ç§€

## ä¸»è¦å‘ç°
1. æ€§èƒ½è¡¨ç°ç¨³å®šï¼ŒP99å“åº”æ—¶é—´ < 5s
2. æˆæœ¬æ§åˆ¶è‰¯å¥½ï¼ŒTokenä½¿ç”¨æ•ˆç‡é«˜
3. å‘ç°3ä¸ªæ€§èƒ½ç“¶é¢ˆéœ€è¦ä¼˜åŒ–

## æ”¹è¿›å»ºè®®
- ä¼˜åŒ–æç¤ºè¯é•¿åº¦ï¼Œé¢„è®¡æå‡15%æ•ˆç‡
- è°ƒæ•´å¹¶å‘å‚æ•°ï¼Œå»ºè®®æå‡è‡³10ä¸ªå¹¶å‘
```

### 2. è¯¦ç»†åˆ†ææŠ¥å‘Š
```markdown
# è¯¦ç»†æ€§èƒ½åˆ†ææŠ¥å‘Š

## 1. æ‰§è¡Œæ—¶é—´åˆ†æ
| æŒ‡æ ‡ | æ•°å€¼ | è¯„ä¼°æ ‡å‡† |
|------|------|----------|
| å¹³å‡å€¼ | 2.3s | âœ“ ä¼˜ç§€ |
| P50 | 2.1s | âœ“ ä¼˜ç§€ |
| P95 | 3.8s | âœ“ è‰¯å¥½ |
| P99 | 4.9s | âœ“ è‰¯å¥½ |

## 2. é”™è¯¯åˆ†æ
- è¶…æ—¶é”™è¯¯: 2.1%
- ç½‘ç»œé”™è¯¯: 1.3%
- å‚æ•°é”™è¯¯: 0.8%
- å…¶ä»–é”™è¯¯: 0.6%

## 3. è¶‹åŠ¿åˆ†æ
```

### 3. ä¼˜åŒ–å»ºè®®æŠ¥å‘Š
```markdown
# æ™ºèƒ½ä¼˜åŒ–å»ºè®®

## é«˜ä¼˜å…ˆçº§å»ºè®®
1. **æç¤ºè¯ä¼˜åŒ–**
   - å½“å‰æ•ˆç‡: 75%
   - ä¼˜åŒ–åé¢„æœŸ: 90%
   - å®æ–½éš¾åº¦: ä¸­ç­‰
   - é¢„æœŸæ”¶ç›Š: +20% æ€§èƒ½æå‡

2. **å¹¶å‘é…ç½®è°ƒä¼˜**
   - å½“å‰å¹¶å‘æ•°: 5
   - å»ºè®®å¹¶å‘æ•°: 10
   - å®æ–½éš¾åº¦: ä½
   - é¢„æœŸæ”¶ç›Š: +25% ååé‡
```

## AIåˆ†æç®—æ³•

### 1. æ€§èƒ½åˆ†æç®—æ³•
```python
class PerformanceAnalyzer:
    def analyze_performance(self, results: List[TestResult]) -> PerformanceAnalysis:
        """æ·±åº¦æ€§èƒ½åˆ†æ"""
        execution_times = [r.execution_time for r in results]

        # åŸºç¡€ç»Ÿè®¡
        avg_time = np.mean(execution_times)
        p50 = np.percentile(execution_times, 50)
        p95 = np.percentile(execution_times, 95)
        p99 = np.percentile(execution_times, 99)

        # æ•ˆç‡è¯„åˆ†ç®—æ³•
        efficiency_score = self.calculate_efficiency_score(execution_times)

        return PerformanceAnalysis(
            execution_time_metrics={
                "avg": avg_time, "p50": p50,
                "p95": p95, "p99": p99
            },
            efficiency_score=efficiency_score
        )

    def calculate_efficiency_score(self, times: List[float]) -> float:
        """æ•ˆç‡è¯„åˆ†ç®—æ³•"""
        # åŸºäºå¤šä¸ªç»´åº¦è®¡ç®—æ•ˆç‡åˆ†
        speed_score = self.calculate_speed_score(times)
        consistency_score = self.calculate_consistency_score(times)

        return (speed_score * 0.7 + consistency_score * 0.3) * 100
```

### 2. æ ¹å› åˆ†æç®—æ³•
```python
def analyze_root_cause(self, failures: List[TestFailure]) -> List[Cause]:
    """æ ¹å› åˆ†æ"""
    causes = []

    # èšç±»åˆ†æ
    error_clusters = self.cluster_failures(failures)

    # å…³è”æ€§åˆ†æ
    for cluster in error_clusters:
        common_patterns = self.find_common_patterns(cluster)
        if common_patterns:
            causes.append(Cause(
                type="common_pattern",
                description=common_patterns.description,
                confidence=common_patterns.confidence,
                affected_workflows=cluster.workflows
            ))

    return causes
```

### 3. è¶‹åŠ¿é¢„æµ‹ç®—æ³•
```python
def predict_performance_trend(self, historical_data: List[PerformanceData]) -> Trend:
    """æ€§èƒ½è¶‹åŠ¿é¢„æµ‹"""
    from sklearn.linear_model import LinearRegression
    from sklearn.preprocessing import PolynomialFeatures

    # å‡†å¤‡æ•°æ®
    X = np.array([[i] for i in range(len(historical_data))])
    y = np.array([data.avg_execution_time for data in historical_data])

    # å¤šé¡¹å¼å›å½’
    poly_features = PolynomialFeatures(degree=2)
    X_poly = poly_features.fit_transform(X)

    model = LinearRegression()
    model.fit(X_poly, y)

    # é¢„æµ‹æœªæ¥è¶‹åŠ¿
    future_X = np.array([[len(historical_data) + i] for i in range(1, 6)])
    future_X_poly = poly_features.transform(future_X)
    predictions = model.predict(future_X)

    return Trend(
        predictions=predictions.tolist(),
        confidence=model.score(X_poly, y),
        trend_direction=self._calculate_trend_direction(predictions)
    )
```

## ä¼˜åŒ–å»ºè®®ç”Ÿæˆ

### 1. æ€§èƒ½ä¼˜åŒ–å»ºè®®
```python
class PerformanceOptimizer:
    def generate_suggestions(self, analysis: PerformanceAnalysis) -> List[OptimizationSuggestion]:
        suggestions = []

        # æ‰§è¡Œæ—¶é—´ä¼˜åŒ–
        if analysis.execution_time_metrics["p99"] > 5.0:
            suggestions.append(
                OptimizationSuggestion(
                    category="performance",
                    title="ä¼˜åŒ–æ‰§è¡Œå»¶è¿Ÿ",
                    description="P99æ‰§è¡Œæ—¶é—´è¿‡é•¿ï¼Œå»ºè®®ä¼˜åŒ–æ¨ç†ç®—æ³•",
                    implementation="å‡å°‘æç¤ºè¯é•¿åº¦ï¼Œä½¿ç”¨æ›´é«˜æ•ˆçš„æ¨¡å‹",
                    expected_improvement="20-30% å»¶è¿Ÿé™ä½",
                    priority="high",
                    difficulty="medium"
                )
            )

        # å¹¶å‘ä¼˜åŒ–
        if analysis.efficiency_score < 70:
            suggestions.append(
                OptimizationSuggestion(
                    category="concurrency",
                    title="æå‡å¹¶å‘èƒ½åŠ›",
                    description="å½“å‰æ•ˆç‡è¾ƒä½ï¼Œå»ºè®®å¢åŠ å¹¶å‘æ•°",
                    implementation="å°†å¹¶å‘æ•°ä»5å¢åŠ åˆ°10",
                    expected_improvement="25% ååé‡æå‡",
                    priority="medium",
                    difficulty="low"
                )
            )

        return suggestions
```

### 2. æˆæœ¬ä¼˜åŒ–å»ºè®®
```python
def suggest_cost_optimizations(self, cost_analysis: CostAnalysis) -> List[CostSuggestion]:
    suggestions = []

    # Tokenä½¿ç”¨ä¼˜åŒ–
    if cost_analysis.token_efficiency < 0.8:
        suggestions.append(
            CostSuggestion(
                area="token_optimization",
                description="Tokenä½¿ç”¨æ•ˆç‡æœ‰å¾…æå‡",
                current_efficiency=cost_analysis.token_efficiency,
                target_efficiency=0.9,
                actions=[
                    "ç²¾ç®€æç¤ºè¯å†…å®¹",
                    "ä½¿ç”¨æ›´é«˜æ•ˆçš„æ¨¡å‹",
                    "å®ç°ç»“æœç¼“å­˜"
                ],
                estimated_savings="15-20%"
            )
        )

    return suggestions
```

## å¯è§†åŒ–å›¾è¡¨

### 1. æ€§èƒ½è¶‹åŠ¿å›¾
```python
def create_performance_chart(self, data: List[PerformanceData]) -> Chart:
    """åˆ›å»ºæ€§èƒ½è¶‹åŠ¿å›¾"""
    return Chart(
        type="line",
        title="æ€§èƒ½è¶‹åŠ¿åˆ†æ",
        x_axis="æ—¶é—´",
        y_axis="æ‰§è¡Œæ—¶é—´(ç§’)",
        datasets=[
            Dataset(name="å¹³å‡æ—¶é—´", data=data.avg_times),
            Dataset(name="P95æ—¶é—´", data=data.p95_times),
            Dataset(name="P99æ—¶é—´", data=data.p99_times)
        ]
    )
```

### 2. é”™è¯¯åˆ†å¸ƒé¥¼å›¾
```python
def create_error_distribution_chart(self, errors: List[ErrorData]) -> Chart:
    """åˆ›å»ºé”™è¯¯åˆ†å¸ƒå›¾"""
    return Chart(
        type="pie",
        title="é”™è¯¯ç±»å‹åˆ†å¸ƒ",
        datasets=[
            Dataset(nameé”™è¯¯ç±»å‹", data=error_distribution),
            Dataset("å æ¯”", data=error_percentages)
        ]
    )
```

## é…ç½®å‚æ•°

```yaml
report:
  # åˆ†æå™¨é…ç½®
  analyzer:
    enable_trend_analysis: True
    enable_root_cause_analysis: True
    enable_ml_prediction: True
    confidence_threshold: 0.8
    min_sample_size: 30

  # æŠ¥å‘Šç”Ÿæˆå™¨é…ç½®
  generator:
    template_dir: "templates/reports"
    output_dir: "reports"
    formats: ["html", "pdf", "excel"]
    include_charts: True
    auto_distribute: True
    distribution_list: ["admin@company.com"]

  # ä¼˜åŒ–å»ºè®®å™¨é…ç½®
  optimizer:
    enable_ai_recommendations: True
    suggestion_categories: ["performance", "cost", "quality", "reliability"]
    max_suggestions_per_category: 5
    min_improvement_threshold: 0.05  # 5%æå‡æ‰å»ºè®®
```

## é«˜çº§åŠŸèƒ½

### 1. è‡ªåŠ¨åŒ–æŠ¥å‘Šåˆ†å‘
```python
# å®šæ—¶æŠ¥å‘Šç”Ÿæˆå’Œåˆ†å‘
scheduler = ReportScheduler()
scheduler.add_cron_job(
    name="daily_performance_report",
    schedule="0 9 * * *",  # æ¯å¤©9ç‚¹
    recipients=["team@company.com"],
    template="daily_report",
    format="html"
)
```

### 2. æ™ºèƒ½å¼‚å¸¸æ£€æµ‹
```python
# åŸºäºMLçš„å¼‚å¸¸æ£€æµ‹
anomaly_detector = MLAnomalyDetector()
anomalies = anomaly_detector.detect(
    data=performance_data,
    sensitivity=0.95,
    min_anomaly_score=0.8
)
```

### 3. è‡ªå®šä¹‰åˆ†æè§„åˆ™
```python
# è‡ªå®šä¹‰åˆ†æè§„åˆ™
custom_analyzer = CustomAnalyzer()
custom_analyzer.add_rule(
    condition=lambda x: x.execution_time > 10,
    action=RuleAction.SUGGEST_OPTIMIZATION,
    message="æ‰§è¡Œæ—¶é—´è¿‡é•¿ï¼Œå»ºè®®ä¼˜åŒ–"
)
```