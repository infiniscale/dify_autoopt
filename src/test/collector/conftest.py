"""
å…±äº«æµ‹è¯• Fixtures for Collector é›†æˆæµ‹è¯•

Date: 2025-11-14
Author: qa-engineer
Description: æä¾›å¯å¤ç”¨çš„æµ‹è¯•æ•°æ®å’Œè¾…åŠ©å‡½æ•°
"""

import pytest
import random
from datetime import datetime, timedelta
from pathlib import Path
from typing import List

from src.collector import TestResult, TestStatus


@pytest.fixture
def sample_results() -> List[TestResult]:
    """
    ç”Ÿæˆ 20 æ¡ç¤ºä¾‹ç»“æœ

    åŒ…å«ä¸åŒçš„å·¥ä½œæµã€çŠ¶æ€å’Œæ€§èƒ½ç‰¹å¾
    """
    results = []
    base_time = datetime.now()

    for i in range(20):
        # ç”Ÿæˆä¸åŒçŠ¶æ€ï¼š75% æˆåŠŸï¼Œ15% å¤±è´¥ï¼Œ5% è¶…æ—¶ï¼Œ5% é”™è¯¯
        if i % 20 < 15:
            status = TestStatus.SUCCESS
            error_msg = None
        elif i % 20 < 18:
            status = TestStatus.FAILED
            error_msg = f"Validation error at step {i}"
        elif i % 20 < 19:
            status = TestStatus.TIMEOUT
            error_msg = "Request timeout after 30s"
        else:
            status = TestStatus.ERROR
            error_msg = "Internal server error"

        result = TestResult(
            workflow_id=f"wf_{i % 3}",  # 3ä¸ªä¸åŒçš„å·¥ä½œæµ
            execution_id=f"exec_{i:03d}",
            timestamp=base_time - timedelta(seconds=i * 10),
            status=status,
            execution_time=0.5 + i * 0.2,  # 0.5s åˆ° 4.3s
            tokens_used=100 + i * 20,  # 100 åˆ° 480
            cost=0.01 + i * 0.002,  # $0.01 åˆ° $0.048
            inputs={"query": f"test_query_{i}", "context": f"context_{i}"},
            outputs={"answer": f"result_{i}" * 50} if status == TestStatus.SUCCESS else {},
            error_message=error_msg,
            prompt_variant=f"variant_{i % 2}" if i % 2 == 0 else None,
            dataset=f"dataset_{i % 3}" if i % 3 == 0 else None
        )
        results.append(result)

    return results


@pytest.fixture
def large_dataset() -> List[TestResult]:
    """
    ç”Ÿæˆ 5,000 æ¡ç»“æœç”¨äºæ€§èƒ½æµ‹è¯•

    æ¨¡æ‹ŸçœŸå®åœºæ™¯çš„æ•°æ®åˆ†å¸ƒ
    """
    results = []
    base_time = datetime.now()
    workflows = [f"wf_{i}" for i in range(10)]

    for i in range(5000):
        # çŠ¶æ€åˆ†å¸ƒï¼š80% æˆåŠŸï¼Œ15% å¤±è´¥ï¼Œ3% è¶…æ—¶ï¼Œ2% é”™è¯¯
        rand_val = random.random()
        if rand_val < 0.80:
            status = TestStatus.SUCCESS
            error_msg = None
        elif rand_val < 0.95:
            status = TestStatus.FAILED
            error_msg = f"Validation failed: reason_{random.randint(1, 5)}"
        elif rand_val < 0.98:
            status = TestStatus.TIMEOUT
            error_msg = "Timeout"
        else:
            status = TestStatus.ERROR
            error_msg = "System error"

        result = TestResult(
            workflow_id=random.choice(workflows),
            execution_id=f"exec_{i:05d}",
            timestamp=base_time - timedelta(seconds=i),
            status=status,
            execution_time=random.uniform(0.1, 10.0),
            tokens_used=random.randint(50, 500),
            cost=random.uniform(0.005, 0.05),
            inputs={"query": f"query_{i}"},
            outputs={"answer": "x" * random.randint(100, 1000)} if status == TestStatus.SUCCESS else {},
            error_message=error_msg,
            prompt_variant=f"v{random.randint(1, 3)}" if random.random() < 0.5 else None,
            dataset=f"ds_{random.randint(1, 5)}" if random.random() < 0.3 else None
        )
        results.append(result)

    return results


@pytest.fixture
def mixed_workflow_results() -> List[TestResult]:
    """
    ç”Ÿæˆå¤šå·¥ä½œæµæ··åˆæ•°æ®ï¼Œç”¨äºå¤šå·¥ä½œæµé›†æˆæµ‹è¯•

    - workflow_1: 50æ¡ï¼Œ80%æˆåŠŸç‡ï¼Œå¿«é€Ÿæ‰§è¡Œ
    - workflow_2: 30æ¡ï¼Œ90%æˆåŠŸç‡ï¼Œä¸­ç­‰æ‰§è¡Œæ—¶é—´
    - workflow_3: 20æ¡ï¼Œ60%æˆåŠŸç‡ï¼Œæ…¢é€Ÿæ‰§è¡Œ
    """
    results = []
    base_time = datetime.now()

    # Workflow 1: 50æ¡ï¼Œ80%æˆåŠŸç‡
    for i in range(50):
        status = TestStatus.SUCCESS if i % 5 != 0 else TestStatus.FAILED
        results.append(TestResult(
            workflow_id="workflow_1",
            execution_id=f"wf1_exec_{i:03d}",
            timestamp=base_time - timedelta(seconds=i),
            status=status,
            execution_time=random.uniform(0.5, 2.0),  # å¿«é€Ÿ
            tokens_used=random.randint(80, 150),
            cost=random.uniform(0.008, 0.015),
            inputs={"query": f"wf1_query_{i}"},
            outputs={"answer": f"wf1_result_{i}" * 30} if status == TestStatus.SUCCESS else {},
            error_message="Workflow 1 error" if status == TestStatus.FAILED else None
        ))

    # Workflow 2: 30æ¡ï¼Œ90%æˆåŠŸç‡
    for i in range(30):
        status = TestStatus.SUCCESS if i % 10 != 0 else TestStatus.FAILED
        results.append(TestResult(
            workflow_id="workflow_2",
            execution_id=f"wf2_exec_{i:03d}",
            timestamp=base_time - timedelta(seconds=i),
            status=status,
            execution_time=random.uniform(2.0, 5.0),  # ä¸­ç­‰
            tokens_used=random.randint(150, 300),
            cost=random.uniform(0.015, 0.030),
            inputs={"query": f"wf2_query_{i}"},
            outputs={"answer": f"wf2_result_{i}" * 40} if status == TestStatus.SUCCESS else {},
            error_message="Workflow 2 error" if status == TestStatus.FAILED else None
        ))

    # Workflow 3: 20æ¡ï¼Œ60%æˆåŠŸç‡
    for i in range(20):
        status = TestStatus.SUCCESS if i % 5 < 3 else TestStatus.FAILED
        results.append(TestResult(
            workflow_id="workflow_3",
            execution_id=f"wf3_exec_{i:03d}",
            timestamp=base_time - timedelta(seconds=i),
            status=status,
            execution_time=random.uniform(5.0, 15.0),  # æ…¢é€Ÿ
            tokens_used=random.randint(300, 600),
            cost=random.uniform(0.030, 0.060),
            inputs={"query": f"wf3_query_{i}"},
            outputs={"answer": f"wf3_result_{i}" * 50} if status == TestStatus.SUCCESS else {},
            error_message="Workflow 3 error" if status == TestStatus.FAILED else None
        ))

    return results


@pytest.fixture
def edge_case_results() -> List[TestResult]:
    """
    ç”Ÿæˆè¾¹ç•Œå’Œå¼‚å¸¸æƒ…å†µçš„æµ‹è¯•æ•°æ®

    åŒ…å«ï¼š
    - æç«¯æ‰§è¡Œæ—¶é—´ï¼ˆæå¿«å’Œææ…¢ï¼‰
    - é›¶ Token æ¶ˆè€—
    - ç©ºè¾“å‡º
    - ç‰¹æ®Šå­—ç¬¦
    """
    base_time = datetime.now()

    return [
        # æå¿«æ‰§è¡Œ
        TestResult(
            workflow_id="edge_fast",
            execution_id="exec_fast_001",
            timestamp=base_time,
            status=TestStatus.SUCCESS,
            execution_time=0.01,
            tokens_used=10,
            cost=0.001,
            inputs={"query": "fast"},
            outputs={"answer": "ok"}
        ),
        # ææ…¢æ‰§è¡Œ
        TestResult(
            workflow_id="edge_slow",
            execution_id="exec_slow_001",
            timestamp=base_time,
            status=TestStatus.SUCCESS,
            execution_time=100.0,
            tokens_used=1000,
            cost=0.1,
            inputs={"query": "slow"},
            outputs={"answer": "x" * 10000}
        ),
        # é›¶ Token
        TestResult(
            workflow_id="edge_zero_token",
            execution_id="exec_zero_001",
            timestamp=base_time,
            status=TestStatus.SUCCESS,
            execution_time=1.0,
            tokens_used=0,
            cost=0.0,
            inputs={"query": "zero"},
            outputs={"answer": ""}
        ),
        # å¤±è´¥ä½†æœ‰è¾“å‡º
        TestResult(
            workflow_id="edge_failed_output",
            execution_id="exec_fail_001",
            timestamp=base_time,
            status=TestStatus.FAILED,
            execution_time=2.0,
            tokens_used=100,
            cost=0.01,
            inputs={"query": "fail"},
            outputs={"partial": "data"},
            error_message="Validation failed after processing"
        ),
        # ç‰¹æ®Šå­—ç¬¦
        TestResult(
            workflow_id="edge_special_chars",
            execution_id="exec_special_001",
            timestamp=base_time,
            status=TestStatus.SUCCESS,
            execution_time=1.5,
            tokens_used=150,
            cost=0.015,
            inputs={"query": "ä¸­æ–‡\næ¢è¡Œ\tåˆ¶è¡¨ç¬¦"},
            outputs={"answer": "ğŸ‰ emoji, quotes: \"test\", backslash: \\"}
        )
    ]


@pytest.fixture
def temp_output_dir(tmp_path: Path) -> Path:
    """
    åˆ›å»ºä¸´æ—¶è¾“å‡ºç›®å½•

    ç”¨äºæµ‹è¯•æ–‡ä»¶å¯¼å‡ºåŠŸèƒ½
    """
    output_dir = tmp_path / "test_output"
    output_dir.mkdir(exist_ok=True)
    return output_dir


@pytest.fixture
def sample_config_yaml(tmp_path: Path) -> Path:
    """
    åˆ›å»ºç¤ºä¾‹é…ç½® YAML æ–‡ä»¶

    ç”¨äºæµ‹è¯•é…ç½®é›†æˆ
    """
    config_content = """
classification:
  thresholds:
    excellent:
      execution_time: 2.0
      token_efficiency: 0.8
    good:
      execution_time: 5.0
      token_efficiency: 0.6
    fair:
      execution_time: 10.0
      token_efficiency: 0.4

export:
  default_filename: "test_results.xlsx"
  include_charts: true
  max_detail_rows: 10000
"""

    config_file = tmp_path / "test_config.yaml"
    config_file.write_text(config_content, encoding="utf-8")
    return config_file


def create_test_result(
    workflow_id: str = "test_wf",
    execution_id: str = "test_exec",
    status: TestStatus = TestStatus.SUCCESS,
    execution_time: float = 1.0,
    tokens_used: int = 100,
    cost: float = 0.01
) -> TestResult:
    """
    è¾…åŠ©å‡½æ•°ï¼šå¿«é€Ÿåˆ›å»ºæµ‹è¯•ç»“æœ

    Args:
        workflow_id: å·¥ä½œæµID
        execution_id: æ‰§è¡ŒID
        status: æ‰§è¡ŒçŠ¶æ€
        execution_time: æ‰§è¡Œæ—¶é—´
        tokens_used: Tokenä½¿ç”¨é‡
        cost: æˆæœ¬

    Returns:
        TestResult: æµ‹è¯•ç»“æœå¯¹è±¡
    """
    return TestResult(
        workflow_id=workflow_id,
        execution_id=execution_id,
        timestamp=datetime.now(),
        status=status,
        execution_time=execution_time,
        tokens_used=tokens_used,
        cost=cost,
        inputs={"query": "test"},
        outputs={"answer": "result" * 20} if status == TestStatus.SUCCESS else {},
        error_message=f"{status.value} error" if status != TestStatus.SUCCESS else None
    )
