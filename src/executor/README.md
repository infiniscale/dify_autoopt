# è°ƒç”¨æ‰§è¡Œæ¨¡å—

## åŠŸèƒ½æ¦‚è¿°

è´Ÿè´£ä»»åŠ¡çš„å¹¶å‘æ‰§è¡Œå’Œè°ƒåº¦ç®¡ç†ï¼Œæä¾›é«˜æ€§èƒ½çš„å¹¶å‘æ‰§è¡Œå™¨ï¼Œæ”¯æŒå¤§è§„æ¨¡å·¥ä½œæµæµ‹è¯•å’Œä»»åŠ¡è°ƒåº¦ã€‚

## æ¨¡å—ç»„æˆ

### 1. å¹¶å‘æ‰§è¡Œå™¨ (concurrent.py)
- å¤šçº¿ç¨‹/å¤šè¿›ç¨‹å¹¶å‘
- ä»»åŠ¡é˜Ÿåˆ—ç®¡ç†
- èµ„æºæ± æ§åˆ¶
- å¼‚å¸¸å¤„ç†æœºåˆ¶

### 2. ä»»åŠ¡è°ƒåº¦å™¨ (scheduler.py)
- ä»»åŠ¡ä¼˜å…ˆçº§ç®¡ç†
- å®šæ—¶ä»»åŠ¡æ‰§è¡Œ
- è´Ÿè½½å‡è¡¡è°ƒåº¦
- èµ„æºç›‘æ§ç®¡ç†

## åŠŸèƒ½ç‰¹æ€§

- ğŸš€ é«˜æ€§èƒ½å¹¶å‘æ‰§è¡Œ
- âš¡ æ™ºèƒ½è´Ÿè½½å‡è¡¡
- ğŸ“Š å®æ—¶èµ„æºç›‘æ§
- ğŸ”„ ä»»åŠ¡è‡ªåŠ¨é‡è¯•
- â° å®šæ—¶ä»»åŠ¡æ”¯æŒ
- ğŸ›¡ï¸ å¼‚å¸¸æ¢å¤æœºåˆ¶

## ä½¿ç”¨ç¤ºä¾‹

```python
# å¹¶å‘æ‰§è¡Œ
from src.executor import ConcurrentExecutor

executor = ConcurrentExecutor(
    max_workers=10,
    timeout=300,
    retry_count=3
)

tasks = [
    {"workflow_id": "wf1", "inputs": {...}},
    {"workflow_id": "wf2", "inputs": {...}},
    {"workflow_id": "wf3", "inputs": {...}}
]

results = executor.run_tasks(tasks)
print(f"æ‰§è¡Œå®Œæˆï¼ŒæˆåŠŸ: {len(results.successful)}, å¤±è´¥: {len(results.failed)}")

# ä»»åŠ¡è°ƒåº¦
from src.executor import TaskScheduler

scheduler = TaskScheduler()

# æ·»åŠ å®šæ—¶ä»»åŠ¡
scheduler.add_cron_task(
    name="daily_test",
    workflow_id="test_workflow",
    schedule="0 2 * * *",  # æ¯å¤©2ç‚¹æ‰§è¡Œ
    inputs={"test_data": "auto_generated"}
)

# å¯åŠ¨è°ƒåº¦å™¨
scheduler.start()
```

## é…ç½®å‚æ•°

```yaml
executor:
  concurrent:
    max_workers: 10
    worker_type: "thread"  # thread/process
    queue_size: 1000
    task_timeout: 300
    retry_count: 3
    retry_delay: 5

  scheduler:
    max_concurrent_tasks: 50
    task_priorities: ["high", "medium", "low"]
    resource_limits:
      cpu_percent: 80
      memory_percent: 70
      network_kbps: 1000

```

## æ‰§è¡Œå™¨ç±»å‹

### 1. çº¿ç¨‹æ± æ‰§è¡Œå™¨
```python
executor = ThreadPoolExecutor(
    max_workers=20,
    queue_size=100,
    daemon=True
)
```

### 2. è¿›ç¨‹æ± æ‰§è¡Œå™¨
```python
executor = ProcessPoolExecutor(
    max_workers=8,
    queue_size=50,
    memory_limit="512MB"
)
```

### 3. å¼‚æ­¥æ‰§è¡Œå™¨
```python
executor = AsyncExecutor(
    max_coroutines=100,
    event_loop_policy="default"
)
```

## ä»»åŠ¡å®šä¹‰

### åŸºç¡€ä»»åŠ¡ç»“æ„
```python
@dataclass
class Task:
    id: str
    workflow_id: str
    inputs: Dict[str, Any]
    priority: str = "medium"
    timeout: int = 300
    retry_count: int = 3
    dependencies: List[str] = None
    metadata: Dict[str, Any] = None
```

### ä»»åŠ¡æ‰§è¡Œç»“æœ
```python
@dataclass
class TaskResult:
    task_id: str
    success: bool
    result: Optional[Dict[str, Any]] = None
    error: Optional[Exception] = None
    execution_time: float = 0.0
    metrics: Dict[str, Any] = None
    timestamp: datetime = None
```

## è°ƒåº¦ç­–ç•¥

### 1. ä¼˜å…ˆçº§è°ƒåº¦
- é«˜: 100åˆ†
- ä¸­: 50åˆ†
- ä½: 10åˆ†

### 2. è´Ÿè½½å‡è¡¡
- CPUä½¿ç”¨ç‡æƒé‡: 40%
- å†…å­˜ä½¿ç”¨ç‡æƒé‡: 30%
- ç½‘ç»œå¸¦å®½æƒé‡: 20%
- ä»»åŠ¡é˜Ÿåˆ—é•¿åº¦æƒé‡: 10%

### 3. èµ„æºé™åˆ¶
```yaml
resource_limits:
  cpu_cores: 8
  memory_mb: 8192
  disk_io_mb_per_sec: 100
  network_mbps: 100
```

## ç›‘æ§æŒ‡æ ‡

### æ‰§è¡ŒçŠ¶æ€ç›‘æ§
- æ´»è·ƒä»»åŠ¡æ•°é‡
- é˜Ÿåˆ—é•¿åº¦
- æˆåŠŸç‡
- å¹³å‡æ‰§è¡Œæ—¶é—´
- èµ„æºä½¿ç”¨ç‡

### æ€§èƒ½æŒ‡æ ‡
- ååé‡ (ä»»åŠ¡/ç§’)
- å»¶è¿Ÿåˆ†å¸ƒ (P50, P95, P99)
- é”™è¯¯ç‡è¶‹åŠ¿
- èµ„æºåˆ©ç”¨ç‡

## å¼‚å¸¸å¤„ç†

### ä»»åŠ¡æ‰§è¡Œå¼‚å¸¸
```python
class TaskExecutionException(Exception):
    def __init__(self, task_id: str, error: Exception):
        self.task_id = task_id
        self.error = error
        super().__init__(f"Task {task_id} failed: {error}")
```

### èµ„æºé™åˆ¶å¼‚å¸¸
```python
class ResourceLimitException(Exception):
    def __init__(self, resource_type: str, current: float, limit: float):
        self.resource_type = resource_type
        self.current = current
        self.limit = limit
        super().__init__(f"Resource {resource_type} exceeded: {current}/{limit}")
```

### è¶…æ—¶å¼‚å¸¸
```python
class TaskTimeoutException(Exception):
    def __init__(self, task_id: str, timeout: int):
        self.task_id = task_id
        self.timeout = timeout
        super().__init__(f"Task {task_id} timed out after {timeout}s")
```

## é«˜çº§åŠŸèƒ½

### ä»»åŠ¡ä¾èµ–ç®¡ç†
```python
# æ”¯æŒä»»åŠ¡é—´ä¾èµ–å…³ç³»
tasks = [
    Task(id="task1", dependencies=[]),
    Task(id="task2", dependencies=["task1"]),
    Task(id="task3", dependencies=["task1", "task2"])
]

executor.run_with_dependencies(tasks)
```

### åŠ¨æ€èµ„æºè°ƒæ•´
```python
# æ ¹æ®è´Ÿè½½åŠ¨æ€è°ƒæ•´å·¥ä½œçº¿ç¨‹æ•°é‡
executor = DynamicExecutor(
    min_workers=5,
    max_workers=50,
    auto_scale_threshold=0.8
)
```

### æ•…éšœæ¢å¤
```python
# è‡ªåŠ¨æ•…éšœæ¢å¤æœºåˆ¶
executor = FaultTolerantExecutor(
    checkpoint_enabled=True,
    auto_recovery=True,
    health_check_interval=30
)
```

## æ€§èƒ½ä¼˜åŒ–å»ºè®®

1. **å¹¶å‘æ•°è°ƒä¼˜**
   - æ ¹æ®CPUæ ¸å¿ƒæ•°è®¾ç½®å·¥ä½œçº¿ç¨‹
   - ç›‘æ§ç³»ç»Ÿèµ„æºä½¿ç”¨æƒ…å†µ
   - é¿å…è¿‡å¤šä¸Šä¸‹æ–‡åˆ‡æ¢

2. **ä»»åŠ¡é˜Ÿåˆ—ç®¡ç†**
   - åˆç†è®¾ç½®é˜Ÿåˆ—å¤§å°
   - ä½¿ç”¨ä¼˜å…ˆçº§é˜Ÿåˆ—
   - å®šæœŸæ¸…ç†è¿‡æœŸä»»åŠ¡

3. **å†…å­˜ç®¡ç†**
   - æ§åˆ¶å¹¶å‘ä»»åŠ¡æ•°é‡
   - åŠæ—¶é‡Šæ”¾ä»»åŠ¡ç»“æœ
   - ç›‘æ§å†…å­˜ä½¿ç”¨è¶‹åŠ¿

4. **ç½‘ç»œä¼˜åŒ–**
   - ä½¿ç”¨è¿æ¥æ± 
   - è®¾ç½®åˆç†çš„è¶…æ—¶æ—¶é—´
   - å®ç°è¯·æ±‚é‡è¯•æœºåˆ¶